{
  "task": "vulnerability detection",
  "filters": {
    "dataset": [
      "PrimeVulPairs"
    ]
  },
  "showByDifficulty": false,
  "generatedAt": "2025-07-04T03:30:58.810Z",
  "results": [
    {
      "rank": 1,
      "model": "Claude-3.7-Sonnet",
      "model_url": "",
      "Accuracy": "-",
      "Precision": "-",
      "Recall": "-",
      "F1 Score": "-",
      "P-C": "80.6",
      "P-V": "5.7",
      "P-B": "7.7",
      "P-R": "6.0"
    },
    {
      "rank": 2,
      "model": "Claude-3.5-Haiku-20241022",
      "model_url": "",
      "Accuracy": "-",
      "Precision": "-",
      "Recall": "-",
      "F1 Score": "-",
      "P-C": "32.3",
      "P-V": "3.8",
      "P-B": "34.3",
      "P-R": "29.5"
    },
    {
      "rank": 3,
      "model": "Claude-3.5-Sonnet-20241022",
      "model_url": "",
      "Accuracy": "-",
      "Precision": "-",
      "Recall": "-",
      "F1 Score": "-",
      "P-C": "77.9",
      "P-V": "8.9",
      "P-B": "5.3",
      "P-R": "7.9"
    },
    {
      "rank": 4,
      "model": "Gemma-3-27B-Instruct",
      "model_url": "",
      "Accuracy": "-",
      "Precision": "-",
      "Recall": "-",
      "F1 Score": "-",
      "P-C": "35.9",
      "P-V": "7.9",
      "P-B": "30.0",
      "P-R": "26.2"
    },
    {
      "rank": 5,
      "model": "GPT-3.5-turbo-0125",
      "model_url": "",
      "Accuracy": "-",
      "Precision": "-",
      "Recall": "-",
      "F1 Score": "-",
      "P-C": "12.7",
      "P-V": "1.9",
      "P-B": "37.1",
      "P-R": "48.4"
    },
    {
      "rank": 6,
      "model": "GPT-4-turbo-2024-04-09",
      "model_url": "",
      "Accuracy": "-",
      "Precision": "-",
      "Recall": "-",
      "F1 Score": "-",
      "P-C": "49.9",
      "P-V": "10.3",
      "P-B": "33.0",
      "P-R": "6.8"
    },
    {
      "rank": 7,
      "model": "GPT-4o-2024-11-20",
      "model_url": "https://openai.com/research/gpt-4",
      "Accuracy": "-",
      "Precision": "-",
      "Recall": "-",
      "F1 Score": "-",
      "P-C": "42.5",
      "P-V": "27.2",
      "P-B": "14.0",
      "P-R": "16.3"
    },
    {
      "rank": 8,
      "model": "Llama-3.1-8B-Instruct",
      "model_url": "",
      "Accuracy": "-",
      "Precision": "-",
      "Recall": "-",
      "F1 Score": "-",
      "P-C": "9.7",
      "P-V": "6.4",
      "P-B": "50.6",
      "P-R": "33.3"
    },
    {
      "rank": 9,
      "model": "Llama-3.1-70B-Instruct",
      "model_url": "",
      "Accuracy": "-",
      "Precision": "-",
      "Recall": "-",
      "F1 Score": "-",
      "P-C": "18.0",
      "P-V": "0.3",
      "P-B": "59.4",
      "P-R": "22.2"
    },
    {
      "rank": 10,
      "model": "o3-mini (Med)",
      "model_url": "",
      "Accuracy": "-",
      "Precision": "-",
      "Recall": "-",
      "F1 Score": "-",
      "P-C": "55.6",
      "P-V": "3.4",
      "P-B": "35.3",
      "P-R": "5.8"
    },
    {
      "rank": 11,
      "model": "Qwen2.5-72B-Instruct",
      "model_url": "",
      "Accuracy": "-",
      "Precision": "-",
      "Recall": "-",
      "F1 Score": "-",
      "P-C": "14.8",
      "P-V": "1.4",
      "P-B": "81.2",
      "P-R": "2.6"
    },
    {
      "rank": 12,
      "model": "Qwen2.5-Coder-32B-Instruct",
      "model_url": "",
      "Accuracy": "-",
      "Precision": "-",
      "Recall": "-",
      "F1 Score": "-",
      "P-C": "24.2",
      "P-V": "7.7",
      "P-B": "49.3",
      "P-R": "18.8"
    },
    {
      "rank": 13,
      "model": "Qwen3-32B",
      "model_url": "",
      "Accuracy": "-",
      "Precision": "-",
      "Recall": "-",
      "F1 Score": "-",
      "P-C": "69.0",
      "P-V": "10.2",
      "P-B": "14.6",
      "P-R": "6.1"
    },
    {
      "rank": 14,
      "model": "Llama-3.3-70B-Instruct",
      "model_url": "",
      "Accuracy": "-",
      "Precision": "-",
      "Recall": "-",
      "F1 Score": "-",
      "P-C": "12.4",
      "P-V": "0.5",
      "P-B": "79.9",
      "P-R": "7.2"
    },
    {
      "rank": 15,
      "model": "DeepSeek-V3",
      "model_url": "",
      "Accuracy": "-",
      "Precision": "-",
      "Recall": "-",
      "F1 Score": "-",
      "P-C": "40.3",
      "P-V": "0.2",
      "P-B": "51.9",
      "P-R": "7.7"
    },
    {
      "rank": 16,
      "model": "DeepSeek-R1",
      "model_url": "",
      "Accuracy": "-",
      "Precision": "-",
      "Recall": "-",
      "F1 Score": "-",
      "P-C": "82.8",
      "P-V": "10.0",
      "P-B": "1.4",
      "P-R": "5.8"
    },
    {
      "rank": 17,
      "model": "o4-mini (Med)",
      "model_url": "",
      "Accuracy": "-",
      "Precision": "-",
      "Recall": "-",
      "F1 Score": "-",
      "P-C": "75.3",
      "P-V": "3.7",
      "P-B": "8.3",
      "P-R": "12.7"
    },
    {
      "rank": 18,
      "model": "Llama-4-Scout-17B-16E-Instruct",
      "model_url": "",
      "Accuracy": "-",
      "Precision": "-",
      "Recall": "-",
      "F1 Score": "-",
      "P-C": "19.8",
      "P-V": "2.2",
      "P-B": "58.5",
      "P-R": "19.5"
    },
    {
      "rank": 19,
      "model": "GPT-4.1-2025-04-14",
      "model_url": "",
      "Accuracy": "-",
      "Precision": "-",
      "Recall": "-",
      "F1 Score": "-",
      "P-C": "90.8",
      "P-V": "2.2",
      "P-B": "0.0",
      "P-R": "7.0"
    },
    {
      "rank": 20,
      "model": "Grok-3-Mini (High)",
      "model_url": "",
      "Accuracy": "-",
      "Precision": "-",
      "Recall": "-",
      "F1 Score": "-",
      "P-C": "78.4",
      "P-V": "12.3",
      "P-B": "3.0",
      "P-R": "6.3"
    },
    {
      "rank": 21,
      "model": "Qwen3-30B-A3B",
      "model_url": "",
      "Accuracy": "-",
      "Precision": "-",
      "Recall": "-",
      "F1 Score": "-",
      "P-C": "61.1",
      "P-V": "9.9",
      "P-B": "20.4",
      "P-R": "8.7"
    },
    {
      "rank": 22,
      "model": "Qwen3-235B-A22B",
      "model_url": "",
      "Accuracy": "-",
      "Precision": "-",
      "Recall": "-",
      "F1 Score": "-",
      "P-C": "85.0",
      "P-V": "6.8",
      "P-B": "2.9",
      "P-R": "5.3"
    },
    {
      "rank": 23,
      "model": "Claude-Sonnet-4",
      "model_url": "https://anthropic.com",
      "Accuracy": "-",
      "Precision": "-",
      "Recall": "-",
      "F1 Score": "-",
      "P-C": "73.3",
      "P-V": "18.0",
      "P-B": "2.8",
      "P-R": "5.8"
    },
    {
      "rank": 24,
      "model": "DeepSeek-R1 (0528)",
      "model_url": "",
      "Accuracy": "-",
      "Precision": "-",
      "Recall": "-",
      "F1 Score": "-",
      "P-C": "72.4",
      "P-V": "19.8",
      "P-B": "2.2",
      "P-R": "5.7"
    },
    {
      "rank": 25,
      "model": "Gemini-2.5-Pro-Preview-05-06",
      "model_url": "",
      "Accuracy": "-",
      "Precision": "-",
      "Recall": "-",
      "F1 Score": "-",
      "P-C": "25.6",
      "P-V": "72.4",
      "P-B": "0.5",
      "P-R": "1.5"
    },
    {
      "rank": 26,
      "model": "Claude-3.5-haiku-20241022",
      "model_url": "",
      "Accuracy": "-",
      "Precision": "-",
      "Recall": "-",
      "F1 Score": "-",
      "P-C": "32.3",
      "P-V": "3.8",
      "P-B": "34.3",
      "P-R": "29.5"
    },
    {
      "rank": 27,
      "model": "Claude-3.5-sonnet-20241022",
      "model_url": "",
      "Accuracy": "-",
      "Precision": "-",
      "Recall": "-",
      "F1 Score": "-",
      "P-C": "77.9",
      "P-V": "8.9",
      "P-B": "5.3",
      "P-R": "7.9"
    },
    {
      "rank": 28,
      "model": "Qwen2.5-32B-Instruct",
      "model_url": "",
      "Accuracy": "-",
      "Precision": "-",
      "Recall": "-",
      "F1 Score": "-",
      "P-C": "24.2",
      "P-V": "7.7",
      "P-B": "49.3",
      "P-R": "18.8"
    },
    {
      "rank": 29,
      "model": "Gemini-2.5-Pro-Preview-03-25",
      "model_url": "",
      "Accuracy": "-",
      "Precision": "-",
      "Recall": "-",
      "F1 Score": "-",
      "P-C": "54.0",
      "P-V": "43.3",
      "P-B": "0.3",
      "P-R": "2.3"
    },
    {
      "rank": 30,
      "model": "Grok-3-Mini-Beta (High)",
      "model_url": "",
      "Accuracy": "-",
      "Precision": "-",
      "Recall": "-",
      "F1 Score": "-",
      "P-C": "78.4",
      "P-V": "12.3",
      "P-B": "3.0",
      "P-R": "6.3"
    }
  ],
  "metadata": {
    "totalResults": 30,
    "hasResults": true
  }
}