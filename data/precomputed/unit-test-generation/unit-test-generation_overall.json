{
  "task": "unit test generation",
  "filters": {},
  "showByDifficulty": false,
  "generatedAt": "2025-09-24T08:13:50.679Z",
  "results": [
    {
      "rank": 1,
      "model": "Claude-3.5-Sonnet-20241022",
      "model_name": "Claude-3.5-Sonnet-20241022",
      "model_url": "",
      "csr": "99.8",
      "line_coverage": "73.22",
      "branch_coverage": "43.24",
      "dataset": "symprompt",
      "lang": "python",
      "task": "unit_test_generation"
    },
    {
      "rank": 2,
      "model": "o4-mini (Med)",
      "model_name": "o4-mini (Med)",
      "model_url": "",
      "csr": "99.8",
      "line_coverage": "81.07",
      "branch_coverage": "47.51",
      "dataset": "symprompt",
      "lang": "python",
      "task": "unit_test_generation"
    },
    {
      "rank": 3,
      "model": "Claude-3.5-Haiku-20241022",
      "model_name": "Claude-3.5-Haiku-20241022",
      "model_url": "",
      "csr": "99.7",
      "line_coverage": "44.59",
      "branch_coverage": "23.49",
      "dataset": "symprompt",
      "lang": "python",
      "task": "unit_test_generation"
    },
    {
      "rank": 4,
      "model": "Qwen-3-235B-A22B",
      "model_name": "Qwen-3-235B-A22B",
      "model_url": "",
      "csr": "99.7",
      "line_coverage": "66.72",
      "branch_coverage": "36.23",
      "dataset": "symprompt",
      "lang": "python",
      "task": "unit_test_generation"
    },
    {
      "rank": 5,
      "model": "Claude-3.7-Sonnet",
      "model_name": "Claude-3.7-Sonnet",
      "model_url": "",
      "csr": "99.3",
      "line_coverage": "75.29",
      "branch_coverage": "43.65",
      "dataset": "symprompt",
      "lang": "python",
      "task": "unit_test_generation"
    },
    {
      "rank": 6,
      "model": "GPT-4-turbo-2024-04-09",
      "model_name": "GPT-4-turbo-2024-04-09",
      "model_url": "",
      "csr": "99.3",
      "line_coverage": "67.70",
      "branch_coverage": "37.11",
      "dataset": "symprompt",
      "lang": "python",
      "task": "unit_test_generation"
    },
    {
      "rank": 7,
      "model": "o3-mini (Med)",
      "model_name": "o3-mini (Med)",
      "model_url": "",
      "csr": "99.3",
      "line_coverage": "69.70",
      "branch_coverage": "41.05",
      "dataset": "symprompt",
      "lang": "python",
      "task": "unit_test_generation"
    },
    {
      "rank": 8,
      "model": "Qwen-2.5-Coder-32B-Instruct",
      "model_name": "Qwen-2.5-Coder-32B-Instruct",
      "model_url": "",
      "csr": "99.3",
      "line_coverage": "64.98",
      "branch_coverage": "35.75",
      "dataset": "symprompt",
      "lang": "python",
      "task": "unit_test_generation"
    },
    {
      "rank": 9,
      "model": "Qwen-3-30B-A3B",
      "model_name": "Qwen-3-30B-A3B",
      "model_url": "",
      "csr": "99.3",
      "line_coverage": "64.89",
      "branch_coverage": "36.52",
      "dataset": "symprompt",
      "lang": "python",
      "task": "unit_test_generation"
    },
    {
      "rank": 10,
      "model": "Claude-4-Sonnet",
      "model_name": "Claude-4-Sonnet",
      "model_url": "",
      "csr": "99.2",
      "line_coverage": "77.05",
      "branch_coverage": "45.23",
      "dataset": "symprompt",
      "lang": "python",
      "task": "unit_test_generation"
    },
    {
      "rank": 11,
      "model": "GPT-4.1-2025-04-14",
      "model_name": "GPT-4.1-2025-04-14",
      "model_url": "",
      "csr": "99.2",
      "line_coverage": "75.42",
      "branch_coverage": "44.48",
      "dataset": "symprompt",
      "lang": "python",
      "task": "unit_test_generation"
    },
    {
      "rank": 12,
      "model": "GPT-5",
      "model_name": "GPT-5",
      "model_url": "",
      "csr": "99.2",
      "line_coverage": "82.63",
      "branch_coverage": "50.28",
      "dataset": "symprompt",
      "lang": "python",
      "task": "unit_test_generation"
    },
    {
      "rank": 13,
      "model": "Gemini-2.5-Pro-05-06",
      "model_name": "Gemini-2.5-Pro-05-06",
      "model_url": "",
      "csr": "99.0",
      "line_coverage": "32.56",
      "branch_coverage": "15.45",
      "dataset": "symprompt",
      "lang": "python",
      "task": "unit_test_generation"
    },
    {
      "rank": 14,
      "model": "Qwen-2.5-72B-Instruct",
      "model_name": "Qwen-2.5-72B-Instruct",
      "model_url": "",
      "csr": "99.0",
      "line_coverage": "64.78",
      "branch_coverage": "34.45",
      "dataset": "symprompt",
      "lang": "python",
      "task": "unit_test_generation"
    },
    {
      "rank": 15,
      "model": "Qwen-3-32B",
      "model_name": "Qwen-3-32B",
      "model_url": "",
      "csr": "99.0",
      "line_coverage": "65.23",
      "branch_coverage": "35.80",
      "dataset": "symprompt",
      "lang": "python",
      "task": "unit_test_generation"
    },
    {
      "rank": 16,
      "model": "DeepSeek-V3",
      "model_name": "DeepSeek-V3",
      "model_url": "",
      "csr": "98.8",
      "line_coverage": "68.61",
      "branch_coverage": "39.04",
      "dataset": "symprompt",
      "lang": "python",
      "task": "unit_test_generation"
    },
    {
      "rank": 17,
      "model": "GPT-3.5-turbo-0125",
      "model_name": "GPT-3.5-turbo-0125",
      "model_url": "",
      "csr": "98.8",
      "line_coverage": "67.47",
      "branch_coverage": "34.09",
      "dataset": "symprompt",
      "lang": "python",
      "task": "unit_test_generation"
    },
    {
      "rank": 18,
      "model": "DeepSeek-R1 (0528)",
      "model_name": "DeepSeek-R1 (0528)",
      "model_url": "",
      "csr": "98.7",
      "line_coverage": "67.39",
      "branch_coverage": "36.16",
      "dataset": "symprompt",
      "lang": "python",
      "task": "unit_test_generation"
    },
    {
      "rank": 19,
      "model": "DeepSeek-R1",
      "model_name": "DeepSeek-R1",
      "model_url": "",
      "csr": "98.5",
      "line_coverage": "69.01",
      "branch_coverage": "38.65",
      "dataset": "symprompt",
      "lang": "python",
      "task": "unit_test_generation"
    },
    {
      "rank": 20,
      "model": "GPT-4o-2024-11-20",
      "model_name": "GPT-4o-2024-11-20",
      "model_url": "https://openai.com/research/gpt-4",
      "csr": "98.5",
      "line_coverage": "69.34",
      "branch_coverage": "39.11",
      "dataset": "symprompt",
      "lang": "python",
      "task": "unit_test_generation"
    },
    {
      "rank": 21,
      "model": "Llama-3.1-70B-Instruct",
      "model_name": "Llama-3.1-70B-Instruct",
      "model_url": "",
      "csr": "98.5",
      "line_coverage": "66.29",
      "branch_coverage": "34.55",
      "dataset": "symprompt",
      "lang": "python",
      "task": "unit_test_generation"
    },
    {
      "rank": 22,
      "model": "Grok-3-Mini (High)",
      "model_name": "Grok-3-Mini (High)",
      "model_url": "",
      "csr": "98.3",
      "line_coverage": "65.86",
      "branch_coverage": "38.42",
      "dataset": "symprompt",
      "lang": "python",
      "task": "unit_test_generation"
    },
    {
      "rank": 23,
      "model": "Llama-3.3-70B-Instruct",
      "model_name": "Llama-3.3-70B-Instruct",
      "model_url": "",
      "csr": "98.3",
      "line_coverage": "66.67",
      "branch_coverage": "35.69",
      "dataset": "symprompt",
      "lang": "python",
      "task": "unit_test_generation"
    },
    {
      "rank": 24,
      "model": "Llama-4-Scout-17B-16E-Instruct",
      "model_name": "Llama-4-Scout-17B-16E-Instruct",
      "model_url": "",
      "csr": "97.7",
      "line_coverage": "68.68",
      "branch_coverage": "35.88",
      "dataset": "symprompt",
      "lang": "python",
      "task": "unit_test_generation"
    },
    {
      "rank": 25,
      "model": "Gemma-3-27B-Instruct",
      "model_name": "Gemma-3-27B-Instruct",
      "model_url": "",
      "csr": "97.5",
      "line_coverage": "64.69",
      "branch_coverage": "34.64",
      "dataset": "symprompt",
      "lang": "python",
      "task": "unit_test_generation"
    },
    {
      "rank": 26,
      "model": "Llama-3.1-8B-Instruct",
      "model_name": "Llama-3.1-8B-Instruct",
      "model_url": "",
      "csr": "96.0",
      "line_coverage": "46.01",
      "branch_coverage": "20.75",
      "dataset": "symprompt",
      "lang": "python",
      "task": "unit_test_generation"
    }
  ],
  "metadata": {
    "totalResults": 26,
    "hasResults": true
  }
}