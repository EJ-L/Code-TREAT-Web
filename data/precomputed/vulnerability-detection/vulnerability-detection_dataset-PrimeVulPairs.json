{
  "task": "vulnerability detection",
  "filters": {
    "dataset": [
      "PrimeVulPairs"
    ]
  },
  "showByDifficulty": false,
  "generatedAt": "2025-07-03T15:10:18.779Z",
  "results": [
    {
      "rank": 1,
      "model": "Claude-Sonnet-4",
      "model_url": "https://anthropic.com",
      "P-C": "73.3",
      "P-V": "18.0",
      "P-B": "2.8",
      "P-R": "5.8",
      "Accuracy": "69.3",
      "Precision": "66.8",
      "Recall": "81.7",
      "F1 Score": "73.5"
    },
    {
      "rank": 2,
      "model": "GPT-4-turbo-2024-04-09",
      "model_url": "",
      "P-C": "49.9",
      "P-V": "10.3",
      "P-B": "33.0",
      "P-R": "6.8",
      "Accuracy": "59.8",
      "Precision": "57.3",
      "Recall": "89.7",
      "F1 Score": "69.9"
    },
    {
      "rank": 3,
      "model": "Gemini-2.5-Pro-Preview-05-06",
      "model_url": "",
      "P-C": "25.6",
      "P-V": "72.4",
      "P-B": "0.5",
      "P-R": "1.5",
      "Accuracy": "54.7",
      "Precision": "54.5",
      "Recall": "93.1",
      "F1 Score": "68.8"
    },
    {
      "rank": 4,
      "model": "GPT-4o-2024-11-20",
      "model_url": "https://openai.com/research/gpt-4",
      "P-C": "42.5",
      "P-V": "27.2",
      "P-B": "14.0",
      "P-R": "16.3",
      "Accuracy": "60.3",
      "Precision": "58.3",
      "Recall": "83.3",
      "F1 Score": "68.6"
    },
    {
      "rank": 5,
      "model": "Claude-3.5-Haiku-20241022",
      "model_url": "",
      "P-C": "32.3",
      "P-V": "3.8",
      "P-B": "34.3",
      "P-R": "29.5",
      "Accuracy": "61.2",
      "Precision": "59.3",
      "Recall": "80.8",
      "F1 Score": "68.4"
    },
    {
      "rank": 6,
      "model": "Llama-3.1-70B-Instruct",
      "model_url": "",
      "P-C": "18.0",
      "P-V": "0.3",
      "P-B": "59.4",
      "P-R": "22.2",
      "Accuracy": "57.2",
      "Precision": "55.5",
      "Recall": "89.1",
      "F1 Score": "68.4"
    },
    {
      "rank": 7,
      "model": "Claude-3.5-haiku-20241022",
      "model_url": "",
      "P-C": "32.3",
      "P-V": "3.8",
      "P-B": "34.3",
      "P-R": "29.5",
      "Accuracy": "61.2",
      "Precision": "59.3",
      "Recall": "80.8",
      "F1 Score": "68.4"
    },
    {
      "rank": 8,
      "model": "Gemma-3-27B-Instruct",
      "model_url": "",
      "P-C": "35.9",
      "P-V": "7.9",
      "P-B": "30.0",
      "P-R": "26.2",
      "Accuracy": "62.0",
      "Precision": "60.6",
      "Recall": "76.9",
      "F1 Score": "67.8"
    },
    {
      "rank": 9,
      "model": "Llama-3.3-70B-Instruct",
      "model_url": "",
      "P-C": "12.4",
      "P-V": "0.5",
      "P-B": "79.9",
      "P-R": "7.2",
      "Accuracy": "62.3",
      "Precision": "61.6",
      "Recall": "73.4",
      "F1 Score": "67.0"
    },
    {
      "rank": 10,
      "model": "DeepSeek-R1",
      "model_url": "",
      "P-C": "82.8",
      "P-V": "10.0",
      "P-B": "1.4",
      "P-R": "5.8",
      "Accuracy": "57.8",
      "Precision": "57.6",
      "Recall": "71.8",
      "F1 Score": "63.9"
    },
    {
      "rank": 11,
      "model": "Gemini-2.5-Pro-Preview-03-25",
      "model_url": "",
      "P-C": "54.0",
      "P-V": "43.3",
      "P-B": "0.3",
      "P-R": "2.3",
      "Accuracy": "57.8",
      "Precision": "58.0",
      "Recall": "68.3",
      "F1 Score": "62.7"
    },
    {
      "rank": 12,
      "model": "GPT-4.1-2025-04-14",
      "model_url": "",
      "P-C": "90.8",
      "P-V": "2.2",
      "P-B": "0.0",
      "P-R": "7.0",
      "Accuracy": "59.8",
      "Precision": "61.2",
      "Recall": "62.2",
      "F1 Score": "61.7"
    },
    {
      "rank": 13,
      "model": "Qwen3-235B-A22B",
      "model_url": "",
      "P-C": "85.0",
      "P-V": "6.8",
      "P-B": "2.9",
      "P-R": "5.3",
      "Accuracy": "55.5",
      "Precision": "56.9",
      "Recall": "59.6",
      "F1 Score": "58.2"
    },
    {
      "rank": 14,
      "model": "Claude-3.5-Sonnet-20241022",
      "model_url": "",
      "P-C": "77.9",
      "P-V": "8.9",
      "P-B": "5.3",
      "P-R": "7.9",
      "Accuracy": "47.7",
      "Precision": "49.9",
      "Recall": "68.9",
      "F1 Score": "57.9"
    },
    {
      "rank": 15,
      "model": "Claude-3.5-sonnet-20241022",
      "model_url": "",
      "P-C": "77.9",
      "P-V": "8.9",
      "P-B": "5.3",
      "P-R": "7.9",
      "Accuracy": "47.7",
      "Precision": "49.9",
      "Recall": "68.9",
      "F1 Score": "57.9"
    },
    {
      "rank": 16,
      "model": "DeepSeek-R1 (0528)",
      "model_url": "",
      "P-C": "72.4",
      "P-V": "19.8",
      "P-B": "2.2",
      "P-R": "5.7",
      "Accuracy": "55.8",
      "Precision": "59.7",
      "Recall": "55.5",
      "F1 Score": "57.5"
    },
    {
      "rank": 17,
      "model": "Grok-3-Mini (High)",
      "model_url": "",
      "P-C": "78.4",
      "P-V": "12.3",
      "P-B": "3.0",
      "P-R": "6.3",
      "Accuracy": "51.2",
      "Precision": "52.6",
      "Recall": "62.5",
      "F1 Score": "57.1"
    },
    {
      "rank": 18,
      "model": "Grok-3-Mini-Beta (High)",
      "model_url": "",
      "P-C": "78.4",
      "P-V": "12.3",
      "P-B": "3.0",
      "P-R": "6.3",
      "Accuracy": "51.2",
      "Precision": "52.6",
      "Recall": "62.5",
      "F1 Score": "57.1"
    },
    {
      "rank": 19,
      "model": "Claude-3.7-Sonnet",
      "model_url": "",
      "P-C": "80.6",
      "P-V": "5.7",
      "P-B": "7.7",
      "P-R": "6.0",
      "Accuracy": "61.8",
      "Precision": "69.1",
      "Recall": "48.1",
      "F1 Score": "56.7"
    },
    {
      "rank": 20,
      "model": "Qwen3-32B",
      "model_url": "",
      "P-C": "69.0",
      "P-V": "10.2",
      "P-B": "14.6",
      "P-R": "6.1",
      "Accuracy": "53.5",
      "Precision": "56.5",
      "Recall": "46.2",
      "F1 Score": "50.8"
    },
    {
      "rank": 21,
      "model": "o4-mini (Med)",
      "model_url": "",
      "P-C": "75.3",
      "P-V": "3.7",
      "P-B": "8.3",
      "P-R": "12.7",
      "Accuracy": "56.3",
      "Precision": "64.6",
      "Recall": "36.2",
      "F1 Score": "46.4"
    },
    {
      "rank": 22,
      "model": "Llama-3.1-8B-Instruct",
      "model_url": "",
      "P-C": "9.7",
      "P-V": "6.4",
      "P-B": "50.6",
      "P-R": "33.3",
      "Accuracy": "54.5",
      "Precision": "61.5",
      "Recall": "33.3",
      "F1 Score": "43.2"
    },
    {
      "rank": 23,
      "model": "Qwen3-30B-A3B",
      "model_url": "",
      "P-C": "61.1",
      "P-V": "9.9",
      "P-B": "20.4",
      "P-R": "8.7",
      "Accuracy": "54.0",
      "Precision": "61.5",
      "Recall": "30.8",
      "F1 Score": "41.0"
    },
    {
      "rank": 24,
      "model": "DeepSeek-V3",
      "model_url": "",
      "P-C": "40.3",
      "P-V": "0.2",
      "P-B": "51.9",
      "P-R": "7.7",
      "Accuracy": "51.5",
      "Precision": "63.6",
      "Recall": "15.7",
      "F1 Score": "25.2"
    },
    {
      "rank": 25,
      "model": "Qwen2.5-72B-Instruct",
      "model_url": "",
      "P-C": "14.8",
      "P-V": "1.4",
      "P-B": "81.2",
      "P-R": "2.6",
      "Accuracy": "52.3",
      "Precision": "73.2",
      "Recall": "13.1",
      "F1 Score": "22.3"
    },
    {
      "rank": 26,
      "model": "o3-mini (Med)",
      "model_url": "",
      "P-C": "55.6",
      "P-V": "3.4",
      "P-B": "35.3",
      "P-R": "5.8",
      "Accuracy": "50.5",
      "Precision": "61.5",
      "Recall": "12.8",
      "F1 Score": "21.2"
    },
    {
      "rank": 27,
      "model": "Qwen2.5-Coder-32B-Instruct",
      "model_url": "",
      "P-C": "24.2",
      "P-V": "7.7",
      "P-B": "49.3",
      "P-R": "18.8",
      "Accuracy": "51.7",
      "Precision": "70.4",
      "Recall": "12.2",
      "F1 Score": "20.8"
    },
    {
      "rank": 28,
      "model": "Qwen2.5-32B-Instruct",
      "model_url": "",
      "P-C": "24.2",
      "P-V": "7.7",
      "P-B": "49.3",
      "P-R": "18.8",
      "Accuracy": "51.7",
      "Precision": "70.4",
      "Recall": "12.2",
      "F1 Score": "20.8"
    },
    {
      "rank": 29,
      "model": "Llama-4-Scout-17B-16E-Instruct",
      "model_url": "",
      "P-C": "19.8",
      "P-V": "2.2",
      "P-B": "58.5",
      "P-R": "19.5",
      "Accuracy": "49.0",
      "Precision": "55.1",
      "Recall": "12.2",
      "F1 Score": "19.9"
    },
    {
      "rank": 30,
      "model": "GPT-3.5-turbo-0125",
      "model_url": "",
      "P-C": "12.7",
      "P-V": "1.9",
      "P-B": "37.1",
      "P-R": "48.4",
      "Accuracy": "45.8",
      "Precision": "40.8",
      "Recall": "9.3",
      "F1 Score": "15.1"
    }
  ],
  "metadata": {
    "totalResults": 30,
    "hasResults": true
  }
}