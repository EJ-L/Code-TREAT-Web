import { ResultEntry, ProcessedResult, TaskType } from './types';

// é«˜æ€§èƒ½æ•°æ®å­˜å‚¨ä¸ç´¢å¼•
class DataStore {
  // ä¸»æ•°æ®å­˜å‚¨
  private allData: ResultEntry[] = [];
  
  // ä¸»è¦ç´¢å¼•
  private indices: {
    byTask: Map<string, Set<number>>;
    byModel: Map<string, Set<number>>;
    byDataset: Map<string, Set<number>>;
    byLang: Map<string, Set<number>>;
    // å¤åˆç´¢å¼•
    byTaskAndDataset: Map<string, Set<number>>;
    byTaskAndModel: Map<string, Set<number>>;
  };
  
  // ç¼“å­˜çš„æŸ¥è¯¢ç»“æœ
  private queryCache: Map<string, ResultEntry[]> = new Map();
  
  // é¢„è®¡ç®—çš„ç»“æœç¼“å­˜
  private precomputedResults: {
    taskResults: Map<string, ResultEntry[]>;
    datasetResults: Map<string, ResultEntry[]>;
    modelResults: Map<string, ResultEntry[]>;
    taskDatasetResults: Map<string, ResultEntry[]>;
  } = {
    taskResults: new Map(),
    datasetResults: new Map(),
    modelResults: new Map(),
    taskDatasetResults: new Map()
  };
  
  constructor() {
    // åˆå§‹åŒ–ç´¢å¼•
    this.indices = {
      byTask: new Map(),
      byModel: new Map(),
      byDataset: new Map(),
      byLang: new Map(),
      byTaskAndDataset: new Map(),
      byTaskAndModel: new Map()
    };
  }
  
  // é‡ç½®æ‰€æœ‰æ•°æ®å’Œç´¢å¼•
  reset(): void {
    this.allData = [];
    this.indices.byTask.clear();
    this.indices.byModel.clear();
    this.indices.byDataset.clear();
    this.indices.byLang.clear();
    this.indices.byTaskAndDataset.clear();
    this.indices.byTaskAndModel.clear();
    this.queryCache.clear();
    
    // æ¸…é™¤é¢„è®¡ç®—ç»“æœ
    this.precomputedResults.taskResults.clear();
    this.precomputedResults.datasetResults.clear();
    this.precomputedResults.modelResults.clear();
    this.precomputedResults.taskDatasetResults.clear();
  }
  
  // æ‰¹é‡æ·»åŠ æ•°æ®å¹¶å»ºç«‹ç´¢å¼•
  addBatch(entries: ResultEntry[]): void {
    if (entries.length === 0) return; // è·³è¿‡ç©ºæ‰¹æ¬¡
    
    const startIdx = this.allData.length;
    
    // æ·»åŠ æ•°æ®
    this.allData.push(...entries);
    
    // æ›´æ–°ç´¢å¼•
    for (let i = 0; i < entries.length; i++) {
      const idx = startIdx + i;
      const entry = entries[i];
      
      // æ›´æ–°ä»»åŠ¡ç´¢å¼•
      const task = entry.task?.toLowerCase() || 'unknown';
      if (!this.indices.byTask.has(task)) {
        this.indices.byTask.set(task, new Set());
      }
      this.indices.byTask.get(task)!.add(idx);
      
      // æ›´æ–°æ¨¡å‹ç´¢å¼•
      const model = entry.model_name || 'unknown';
      if (!this.indices.byModel.has(model)) {
        this.indices.byModel.set(model, new Set());
      }
      this.indices.byModel.get(model)!.add(idx);
      
      // æ›´æ–°æ•°æ®é›†ç´¢å¼•
      const dataset = entry.dataset?.toLowerCase() || 'unknown';
      if (!this.indices.byDataset.has(dataset)) {
        this.indices.byDataset.set(dataset, new Set());
      }
      this.indices.byDataset.get(dataset)!.add(idx);
      
      // æ›´æ–°è¯­è¨€ç´¢å¼•
      const lang = entry.lang || 'unknown';
      if (!this.indices.byLang.has(lang)) {
        this.indices.byLang.set(lang, new Set());
      }
      this.indices.byLang.get(lang)!.add(idx);
      
      // æ›´æ–°å¤åˆç´¢å¼•ï¼šä»»åŠ¡+æ•°æ®é›†
      const taskDatasetKey = `${task}:${dataset}`;
      if (!this.indices.byTaskAndDataset.has(taskDatasetKey)) {
        this.indices.byTaskAndDataset.set(taskDatasetKey, new Set());
      }
      this.indices.byTaskAndDataset.get(taskDatasetKey)!.add(idx);
      
      // æ›´æ–°å¤åˆç´¢å¼•ï¼šä»»åŠ¡+æ¨¡å‹
      const taskModelKey = `${task}:${model}`;
      if (!this.indices.byTaskAndModel.has(taskModelKey)) {
        this.indices.byTaskAndModel.set(taskModelKey, new Set());
      }
      this.indices.byTaskAndModel.get(taskModelKey)!.add(idx);
    }
    
    // æ¸…é™¤æŸ¥è¯¢ç¼“å­˜
    this.queryCache.clear();
    
    // é¢„è®¡ç®—æ–°çš„ç»“æœ - ä»…å½“æ‰¹é‡å¤§å°è¶…è¿‡é˜ˆå€¼æ—¶æ‰é¢„è®¡ç®—
    // è¾ƒå°çš„æ‰¹æ¬¡ç§¯ç´¯åå†ä¸€æ¬¡æ€§é¢„è®¡ç®—ï¼Œæé«˜æ€§èƒ½
    if (entries.length > 50) {
      this.precomputeResults();
    }
  }
  
  // è·å–æ‰€æœ‰æ•°æ®
  getAll(): ResultEntry[] {
    return this.allData;
  }
  
  // æŒ‰ä»»åŠ¡æŸ¥è¯¢
  getByTask(task: string): ResultEntry[] {
    const taskLower = task.toLowerCase();
    const precomputed = this.precomputedResults.taskResults.get(taskLower);
    if (precomputed) {
      return precomputed;
    }
    
    // å¦‚æœæ²¡æœ‰é¢„è®¡ç®—ç»“æœï¼Œä½¿ç”¨åŸæœ‰é€»è¾‘
    const indices = this.indices.byTask.get(taskLower);
    if (!indices) return [];
    return Array.from(indices).map(idx => this.allData[idx]);
  }
  
  // æŒ‰æ¨¡å‹åç§°æŸ¥è¯¢
  getByModel(model: string): ResultEntry[] {
    const cacheKey = `model:${model}`;
    
    if (this.queryCache.has(cacheKey)) {
      return this.queryCache.get(cacheKey)!;
    }
    
    const indices = this.indices.byModel.get(model);
    if (!indices) return [];
    
    const result = Array.from(indices).map(idx => this.allData[idx]);
    this.queryCache.set(cacheKey, result);
    return result;
  }
  
  // æŒ‰æ•°æ®é›†æŸ¥è¯¢
  getByDataset(dataset: string): ResultEntry[] {
    const datasetLower = dataset.toLowerCase();
    const precomputed = this.precomputedResults.datasetResults.get(datasetLower);
    if (precomputed) {
      return precomputed;
    }
    
    const indices = this.indices.byDataset.get(datasetLower);
    if (!indices) return [];
    return Array.from(indices).map(idx => this.allData[idx]);
  }
  
  // æŒ‰ä»»åŠ¡å’Œæ•°æ®é›†ç»„åˆæŸ¥è¯¢
  getByTaskAndDataset(task: string, dataset: string): ResultEntry[] {
    const key = `${task.toLowerCase()}:${dataset.toLowerCase()}`;
    const precomputed = this.precomputedResults.taskDatasetResults.get(key);
    if (precomputed) {
      return precomputed;
    }
    
    const indices = this.indices.byTaskAndDataset.get(key);
    if (!indices) return [];
    return Array.from(indices).map(idx => this.allData[idx]);
  }
  
  // æŒ‰ä»»åŠ¡å’Œæ¨¡å‹ç»„åˆæŸ¥è¯¢
  getByTaskAndModel(task: string, model: string): ResultEntry[] {
    const taskLower = task.toLowerCase();
    const cacheKey = `task:${taskLower}:model:${model}`;
    
    if (this.queryCache.has(cacheKey)) {
      return this.queryCache.get(cacheKey)!;
    }
    
    const key = `${taskLower}:${model}`;
    const indices = this.indices.byTaskAndModel.get(key);
    if (!indices) return [];
    
    const result = Array.from(indices).map(idx => this.allData[idx]);
    this.queryCache.set(cacheKey, result);
    return result;
  }
  
  // è·å–æ‰€æœ‰å¯ç”¨ä»»åŠ¡
  getAvailableTasks(): string[] {
    return Array.from(this.indices.byTask.keys());
  }
  
  // è·å–æ‰€æœ‰å¯ç”¨æ•°æ®é›†
  getAvailableDatasets(): string[] {
    return Array.from(this.indices.byDataset.keys());
  }
  
  // è·å–æ‰€æœ‰å¯ç”¨æ¨¡å‹
  getAvailableModels(): string[] {
    return Array.from(this.indices.byModel.keys());
  }
  
  // è·å–ç‰¹å®šä»»åŠ¡ä¸‹çš„æ‰€æœ‰å¯ç”¨æ•°æ®é›†
  getAvailableDatasetsForTask(task: string): string[] {
    const taskLower = task.toLowerCase();
    const result: string[] = [];
    
    this.indices.byTaskAndDataset.forEach((_, key) => {
      if (key.startsWith(`${taskLower}:`)) {
        result.push(key.split(':')[1]);
      }
    });
    
    return result;
  }
  
  // è·å–ç‰¹å®šä»»åŠ¡ä¸‹çš„æ‰€æœ‰å¯ç”¨æ¨¡å‹
  getAvailableModelsForTask(task: string): string[] {
    const taskLower = task.toLowerCase();
    const result: string[] = [];
    
    this.indices.byTaskAndModel.forEach((_, key) => {
      if (key.startsWith(`${taskLower}:`)) {
        result.push(key.split(':')[1]);
      }
    });
    
    return result;
  }
  
  // é¢„å¤„ç†æ‰€æœ‰æ•°æ®
  private precomputeResults(): void {
    // æ¸…é™¤æ—§çš„é¢„è®¡ç®—ç»“æœ
    this.precomputedResults.taskResults.clear();
    this.precomputedResults.datasetResults.clear();
    this.precomputedResults.modelResults.clear();
    this.precomputedResults.taskDatasetResults.clear();
    
    // é¢„å¤„ç†æ¯ä¸ªä»»åŠ¡çš„æ•°æ® - ä½¿ç”¨æ•°ç»„è€Œä¸æ˜¯Mapéå†æ•ˆç‡æ›´é«˜
    Array.from(this.indices.byTask.entries()).forEach(([task, indices]) => {
      const entries = Array.from(indices).map(idx => this.allData[idx]);
      this.precomputedResults.taskResults.set(task, entries);
    });
    
    // é¢„å¤„ç†æ¯ä¸ªæ•°æ®é›†çš„æ•°æ®
    Array.from(this.indices.byDataset.entries()).forEach(([dataset, indices]) => {
      // ä»…é¢„è®¡ç®—ç»å¸¸è®¿é—®çš„æ•°æ®é›†ï¼Œæé«˜æ€§èƒ½
      if (dataset === 'unknown') return;
      const entries = Array.from(indices).map(idx => this.allData[idx]);
      this.precomputedResults.datasetResults.set(dataset, entries);
    });
    
    // é¢„å¤„ç†æ¯ä¸ªæ¨¡å‹çš„æ•°æ® - è¿™éƒ¨åˆ†å¯èƒ½ä¸å¤ªå¸¸ç”¨ï¼Œè·³è¿‡æé«˜æ€§èƒ½
    // this.indices.byModel.forEach((indices, model) => {
    //   const entries = Array.from(indices).map(idx => this.allData[idx]);
    //   this.precomputedResults.modelResults.set(model, entries);
    // });
    
    // é¢„å¤„ç†ä»»åŠ¡+æ•°æ®é›†ç»„åˆçš„æ•°æ® - æŒ‰éœ€åŠ è½½ï¼Œä¸é¢„å…ˆè®¡ç®—
    // this.indices.byTaskAndDataset.forEach((indices, key) => {
    //   const entries = Array.from(indices).map(idx => this.allData[idx]);
    //   this.precomputedResults.taskDatasetResults.set(key, entries);
    // });
  }
}

// å®ä¾‹åŒ–æ•°æ®å­˜å‚¨
const dataStore = new DataStore();

// æ–‡ä»¶ç¼“å­˜
const fileCache: Map<string, ResultEntry[]> = new Map();

// Loading state management
let isLoadingData = false;
let loadingDataPromise: Promise<ResultEntry[]> | null = null;

export const taskDirectories: Record<string, string> = {
  'code generation': 'data/code-generation',
  'code translation': 'data/code-translation',
  'code summarization': 'data/code-summarization',
  // 'code execution': 'data/code-execution',
  'vulnerability detection': 'data/vulnerability-detection',
  'code review': 'data/code-review',
  'input prediction': 'data/input_prediction',
  'output prediction': 'data/output_prediction',
  'code-web': 'data/code-web',
  'interaction-2-code': 'data/interaction-2-code',
  'code-robustness': 'data/code-robustness',
  'mr-web': 'data/mr-web'
};

// åŠ è½½å•ä¸ªæ–‡ä»¶çš„å‡½æ•°
async function loadJsonlFile(directory: string, file: string): Promise<ResultEntry[]> {
  const cacheKey = `${directory}/${file}`;
  
  // æ£€æŸ¥ç¼“å­˜
  if (fileCache.has(cacheKey)) {
    return fileCache.get(cacheKey)!;
  }

  try {
    // å¼‚æ­¥åŠ è½½æ–‡ä»¶æ•°æ®
    const response = await fetch(`/api/files?directory=${directory}&file=${file}`);
    if (!response.ok) {
      throw new Error(`HTTP error! status: ${response.status}`);
    }
    
    const responseData = await response.json();
    
    // This function is specifically for JSONL files (arrays of entries)
    if (!responseData.data || !Array.isArray(responseData.data)) {
      throw new Error('Invalid data format - expected JSONL format with data array');
    }
    
    // ç¼“å­˜æ•°æ®
    fileCache.set(cacheKey, responseData.data);
    return responseData.data;
    
  } catch (error) {
    console.error(`åŠ è½½æ–‡ä»¶å¤±è´¥: ${directory}/${file}`, error);
    return [];
  }
}

// è·å–æ–‡ä»¶ç¼“å­˜æ•°æ®
export function getCachedFileData(directory: string, file: string): ResultEntry[] | null {
  const cacheKey = `${directory}/${file}`;
  return fileCache.has(cacheKey) ? fileCache.get(cacheKey)! : null;
}

// æ‰¹é‡åŠ è½½æ‰€æœ‰æ•°æ®
export async function loadAllData(): Promise<ResultEntry[]> {
  // æ£€æŸ¥æ˜¯å¦å·²æœ‰æ•°æ®
  if (dataStore.getAll().length > 0) {
    return dataStore.getAll();
  }
  
  // If currently loading, wait for the existing promise
  if (isLoadingData && loadingDataPromise) {
    return loadingDataPromise;
  }
  
  // Set loading flag and create promise
  isLoadingData = true;
  loadingDataPromise = performDataLoad();
  
  try {
    const result = await loadingDataPromise;
    return result;
  } finally {
    isLoadingData = false;
    loadingDataPromise = null;
  }
}

async function performDataLoad(): Promise<ResultEntry[]> {
  try {
    // First try to ensure GitHub data is downloaded locally
    console.log('Checking if GitHub data needs to be downloaded...');
    
    try {
      const downloadResponse = await fetch('/api/download-github-data', {
        method: 'POST'
      });
      
      if (downloadResponse.ok) {
        const result = await downloadResponse.json();
        console.log('GitHub data download result:', result.message);
      } else {
        console.warn('Failed to download GitHub data, will use existing local data if available');
      }
    } catch (downloadError) {
      console.warn('Error downloading GitHub data:', downloadError);
    }
    
    console.log('Loading data from local files...');
    
    // Fallback to local file system
    // è·å–æ‰€æœ‰ç›®å½•çš„æ–‡ä»¶åˆ—è¡¨
    const directoriesPromises = Object.entries(taskDirectories)
      .filter(([taskType]) => taskType !== 'overall')
      .map(async ([taskType, directory]) => {
        try {
          const response = await fetch(`/api/files?directory=${directory}`);
          if (!response.ok) {
            console.warn(`è·å–ç›®å½•å¤±è´¥: ${directory}`);
            return { taskType, directory, files: [] };
          }
          
          const files = await response.json();
          return { taskType, directory, files };
        } catch (error) {
          console.error(`å¤„ç†ç›®å½•å¤±è´¥: ${directory}`, error);
          return { taskType, directory, files: [] };
        }
      });
    
    // å¹¶è¡Œè·å–æ‰€æœ‰ç›®å½•çš„æ–‡ä»¶åˆ—è¡¨
    const directories = await Promise.all(directoriesPromises);
    
    // ä¸²è¡Œå¤„ç†æ¯ä¸ªç›®å½•ï¼ˆé¿å…å†…å­˜é—®é¢˜ï¼‰
    for (const { taskType, directory, files } of directories) {
      if (files.length === 0) continue;
      
      // æ‰¹é‡å¤„ç†æ–‡ä»¶ï¼Œæ¯æ‰¹æœ€å¤š5ä¸ªæ–‡ä»¶å¹¶è¡ŒåŠ è½½
      const batchSize = 5;
      for (let i = 0; i < files.length; i += batchSize) {
        const batch = files.slice(i, i + batchSize);
        
        // å¹¶è¡ŒåŠ è½½ä¸€æ‰¹æ–‡ä»¶ (åªå¤„ç†JSONLæ–‡ä»¶)
        const batchResults = await Promise.all(
          batch.filter((file: string) => file.endsWith('.jsonl')).map(async (file: string) => {
            try {
              const fileData = await loadJsonlFile(directory, file);
              
              // Log when loading input_prediction files
              if (taskType === 'input prediction' && fileData.length > 0) {
                console.log(`Loaded input prediction file: ${file} with ${fileData.length} entries`);
              }
              
              // ç‰¹åˆ«è®°å½•code reviewæ–‡ä»¶çš„å†…å®¹ï¼ˆä»…åœ¨ç¬¬ä¸€æ¬¡åŠ è½½æ—¶ï¼‰
              if (taskType === 'code review' && fileData.length > 0 && i === 0 && file === batch[0]) {
                console.log(`Loaded code review file with ${fileData.length} entries`);
              }
              
              // å¤„ç†æ•°æ®ï¼Œç¡®ä¿languageå­—æ®µè¢«æ­£ç¡®æ˜ å°„åˆ°langå­—æ®µ
              return fileData.map(entry => {
                // å¦‚æœæœ‰languageå­—æ®µä½†æ²¡æœ‰langå­—æ®µï¼Œå°†languageå­—æ®µçš„å€¼å¤åˆ¶åˆ°langå­—æ®µ
                if (entry.language && !entry.lang) {
                  const result = {...entry, lang: entry.language, task: taskType};
                  // For mr-web, preserve the original task as subtask
                  if (taskType === 'mr-web' && entry.task) {
                    result.subtask = entry.task;
                  }
                  // For mr-web, preserve the method field
                  if (taskType === 'mr-web' && entry.method) {
                    result.method = entry.method;
                  }
                  // Preserve domain field if it exists
                  if ((entry as any).domain) {
                    result.domain = (entry as any).domain;
                  }
                  return result;
                }
                const result = {...entry, task: taskType};
                // For mr-web, preserve the original task as subtask
                if (taskType === 'mr-web' && entry.task) {
                  result.subtask = entry.task;
                }
                // For mr-web, preserve the method field
                if (taskType === 'mr-web' && entry.method) {
                  result.method = entry.method;
                }
                // Preserve domain field if it exists
                if ((entry as any).domain) {
                  result.domain = (entry as any).domain;
                }
                
                return result;
              });
            } catch (error) {
              console.error(`å¤„ç†æ–‡ä»¶å¤±è´¥: ${file}`, error);
              return [];
            }
          })
        );
        
        // æ‰¹é‡æ·»åŠ åˆ°æ•°æ®å­˜å‚¨
        for (const entryBatch of batchResults) {
          if (entryBatch.length > 0) {
            dataStore.addBatch(entryBatch);
          }
        }
      }
    }
    
    // æ£€æŸ¥æ˜¯å¦åŠ è½½åˆ°æ•°æ®
    const allData = dataStore.getAll();
    if (allData.length === 0) {
      console.log('æ²¡æœ‰åŠ è½½åˆ°æ•°æ®ï¼Œè¿”å›æ¨¡æ‹Ÿæ•°æ®');
      const mockData = getMockData();
      dataStore.addBatch(mockData);
      return mockData;
    }
    
    return allData;
    
  } catch (error) {
    console.error('åŠ è½½æ•°æ®è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯:', error);
    
    // If both GitHub and local loading fail, use mock data
    console.log('Both GitHub and local data loading failed, using mock data');
    const mockData = getMockData();
    dataStore.addBatch(mockData);
    return mockData;
  }
}

// è·å–ç‰¹å®šä»»åŠ¡çš„æ•°æ®
export function getTaskData(taskType: string): ResultEntry[] {
  return dataStore.getByTask(taskType);
}

// è·å–ç‰¹å®šæ•°æ®é›†çš„æ•°æ®
export function getDatasetData(dataset: string): ResultEntry[] {
  return dataStore.getByDataset(dataset);
}

// è·å–ç‰¹å®šæ¨¡å‹çš„æ•°æ®
export function getModelData(modelName: string): ResultEntry[] {
  return dataStore.getByModel(modelName);
}

// è·å–ç‰¹å®šä»»åŠ¡å’Œæ•°æ®é›†çš„æ•°æ®
export function getTaskAndDatasetData(taskType: string, dataset: string): ResultEntry[] {
  return dataStore.getByTaskAndDataset(taskType, dataset);
}

// æ¸…é™¤æ‰€æœ‰ç¼“å­˜
export function clearCache(): void {
  dataStore.reset();
  fileCache.clear();
  isLoadingData = false;
  loadingDataPromise = null;
}

// è·å–æ‰€æœ‰å¯ç”¨çš„ä»»åŠ¡
export function getAvailableTasks(): string[] {
  return dataStore.getAvailableTasks();
}

// è·å–æ‰€æœ‰å¯ç”¨çš„æ•°æ®é›†
export function getAvailableDatasets(): string[] {
  return dataStore.getAvailableDatasets();
}

// è·å–æ‰€æœ‰å¯ç”¨çš„æ¨¡å‹
export function getAvailableModels(): string[] {
  return dataStore.getAvailableModels();
}

// æä¾›æ¨¡æ‹Ÿæ•°æ®
function getMockData(): ResultEntry[] {
  return [
    {
      id: 'mock-1',
      model_name: 'GPT-4',
      task: 'code generation',
      lang: 'python',
      dataset: 'HackerRank',
      metrics: {
        'pass@1': 0.85,
        'pass@3': 0.92,
        'pass@5': 0.95
      }
    },
    {
      id: 'mock-2',
      model_name: 'Claude 3',
      task: 'code generation',
      lang: 'python',
      dataset: 'HackerRank',
      metrics: {
        'pass@1': 0.82,
        'pass@3': 0.90,
        'pass@5': 0.93
      }
    },
    {
      id: 'mock-3',
      model_name: 'Llama 3',
      task: 'code generation',
      lang: 'python',
      dataset: 'HackerRank',
      metrics: {
        'pass@1': 0.78,
        'pass@3': 0.88,
        'pass@5': 0.92
      }
    },
    {
      id: 'mock-4',
      model_name: 'CodeLlama',
      task: 'code generation',
      lang: 'python',
      dataset: 'HackerRank',
      metrics: {
        'pass@1': 0.76,
        'pass@3': 0.85,
        'pass@5': 0.90
      }
    },
    {
      id: 'mock-5',
      model_name: 'GPT-4',
      task: 'code translation',
      lang: 'python',
      source_lang: 'python',
      target_lang: 'java',
      dataset: 'CodeTransOcean',
      metrics: {
        'pass@1': 0.80,
        'CodeBLEU': 0.75
      }
    },
    {
      id: 'mock-6',
      model_name: 'Claude 3',
      task: 'code summarization',
      lang: 'javascript',
      dataset: 'GitHub',
      metrics: {
        'LLMJudge': 4.2
      }
    }
  ];
}

export function processResult(entry: ResultEntry): ProcessedResult {
  // Convert simplified result entry to standardized ProcessedResult format
  const processedResult: ProcessedResult = {
    modelId: `${entry.model_name}-${entry.dataset || 'unknown'}-${entry.task || 'unknown'}`,
    modelName: entry.model_name,
    dataset: entry.dataset || 'Unknown',
    task: entry.task || 'Unknown',
    sourceLang: entry.source_lang || null,
    lang: entry.lang || (entry.language || 'Unknown'),
    targetLang: entry.target_lang || null,
    domain: entry.domain || undefined,
    pass1: entry.metrics?.['pass@1'] !== undefined ? entry.metrics['pass@1'] : null, 
    pass3: entry.metrics?.['pass@3'] !== undefined ? entry.metrics['pass@3'] : null,
    pass5: entry.metrics?.['pass@5'] !== undefined ? entry.metrics['pass@5'] : null,
    executionAccuracy: entry.metrics?.['ExecutionAccuracy'] !== undefined ? entry.metrics['ExecutionAccuracy'] : null,
    codebleu: entry.metrics?.['CodeBLEU'] !== undefined ? entry.metrics['CodeBLEU'] : null,
    llmjudge: (typeof entry.metrics?.['LLMJudge'] === 'number') ? entry.metrics['LLMJudge'] : null,
    difficulty: entry.difficulty || null,
    // Initialize difficulty metrics as null
    easyPass1: null,
    easyPass3: null,
    easyPass5: null,
    mediumPass1: null,
    mediumPass3: null,
    mediumPass5: null,
    hardPass1: null,
    hardPass3: null,
    hardPass5: null
  };

  // Special handling for difficulty information
  if (entry.difficulty) {
    console.log(`Processing difficulty metrics: ${entry.difficulty}, pass@1:`, entry.metrics?.['pass@1']);
    
    // Assign metrics to the appropriate difficulty category
    switch (entry.difficulty.toLowerCase()) {
      case 'easy':
        processedResult.easyPass1 = entry.metrics?.['pass@1'] !== undefined ? entry.metrics['pass@1'] : null;
        processedResult.easyPass3 = entry.metrics?.['pass@3'] !== undefined ? entry.metrics['pass@3'] : null;
        processedResult.easyPass5 = entry.metrics?.['pass@5'] !== undefined ? entry.metrics['pass@5'] : null;
        break;
      case 'medium':
        processedResult.mediumPass1 = entry.metrics?.['pass@1'] !== undefined ? entry.metrics['pass@1'] : null;
        processedResult.mediumPass3 = entry.metrics?.['pass@3'] !== undefined ? entry.metrics['pass@3'] : null;
        processedResult.mediumPass5 = entry.metrics?.['pass@5'] !== undefined ? entry.metrics['pass@5'] : null;
        break;
      case 'hard':
        processedResult.hardPass1 = entry.metrics?.['pass@1'] !== undefined ? entry.metrics['pass@1'] : null;
        processedResult.hardPass3 = entry.metrics?.['pass@3'] !== undefined ? entry.metrics['pass@3'] : null;
        processedResult.hardPass5 = entry.metrics?.['pass@5'] !== undefined ? entry.metrics['pass@5'] : null;
        break;
    }
  }

  return processedResult;
}

// æ ¹æ®æ•°æ®é›†åç§°æˆ–å…¶ä»–å­—æ®µæ¨æ–­ä»»åŠ¡ç±»å‹
function inferTaskType(entry: ResultEntry): string {
  // ä»æ•°æ®é›†åç§°æ¨æ–­
  const dataset = entry.dataset?.toLowerCase() || '';
  if (dataset.includes('translation')) return 'code translation';
  if (dataset.includes('generation')) return 'code generation';
  if (dataset.includes('summary') || dataset.includes('summarization')) return 'code summarization';
  if (dataset.includes('execution')) return 'code execution';
  
  // ä»æŒ‡æ ‡æ¨æ–­
  if (entry.metrics?.['CodeBLEU'] !== undefined) return 'code translation';
  // if (entry.metrics?.['ExecutionAccuracy'] !== undefined) return 'code execution';
  if (entry.metrics?.['LLMJudge'] !== undefined) return 'code summarization';
  if (entry.metrics?.['gpt-4o'] !== undefined) return 'code review';
  
  // ä»è¯­è¨€å­—æ®µæ¨æ–­
  if (entry.source_lang && entry.target_lang) return 'code translation';
  
  // é»˜è®¤ä¸ºä»£ç ç”Ÿæˆ
  console.warn('Could not infer task type, defaulting to code generation:', entry);
  return 'code generation';
}

// æ·»åŠ é˜²æŠ–å‡½æ•°
function debounce<T extends (...args: any[]) => any>(
  func: T,
  wait: number
): (...args: Parameters<T>) => void {
  let timeout: NodeJS.Timeout | null = null;
  
  return function(this: any, ...args: Parameters<T>) {
    if (timeout) {
      clearTimeout(timeout);
    }
    
    timeout = setTimeout(() => {
      func.apply(this, args);
      timeout = null;
    }, wait);
  };
}

// å¯¼å‡ºé˜²æŠ–ç‰ˆæœ¬çš„æ•°æ®è·å–å‡½æ•°
export const debouncedGetTaskData = debounce(getTaskData, 100);
export const debouncedGetDatasetData = debounce(getDatasetData, 100);
export const debouncedGetModelData = debounce(getModelData, 100);
export const debouncedGetTaskAndDatasetData = debounce(getTaskAndDatasetData, 100);

// Add interface for precomputed data structure
interface PrecomputedResult {
  rank: number;
  model: string;
  model_url?: string;
  [key: string]: any; // For metrics like pass@1, LLM Judge, etc.
}

interface PrecomputedData {
  [modelName: string]: {
    [combinationKey: string]: PrecomputedResult;
  };
}

// Cache for precomputed data
const precomputedCache = new Map<string, PrecomputedData>();

// Function to generate combination key from filters
function generateCombinationKey(task: string, filters: any, showByDifficulty: boolean): string {
  const parts: string[] = [];
  
  // Note: The consolidated files don't include task name in the combination keys
  
  // Add filter parts in consistent order - must match the naming convention used in consolidated files
  const filterMapping: Record<string, string> = {
    datasets: 'dataset',
    modality: 'modality', 
    modalities: 'modality',
    langs: 'modality',
    knowledge: 'knowledge',
    reasoning: 'reasoning',
    robustness: 'robustness',
    privacy: 'privacy',
    llmJudges: 'llmJudges',
    framework: 'framework'
  };
  
  // Process filters in the order they appear in the actual combination keys
  const orderedFilterKeys = ['datasets', 'modality', 'modalities', 'langs', 'knowledge', 'reasoning', 'robustness', 'privacy', 'llmJudges', 'framework'];
  
  orderedFilterKeys.forEach(filterKey => {
    const values = filters[filterKey];
    
    if (values && values.length > 0) {
      const mappedKey = filterMapping[filterKey];
      if (mappedKey) {
        const sortedValues = [...values].sort();
        const part = `${mappedKey}-${sortedValues.join('-')}`;
        parts.push(part);
      }
    }
  });
  
  // If no filters applied, use 'overall'
  const result = parts.length === 0 ? 'overall' : parts.join('_');
  
  return result;
}

// Function to load precomputed data for a task
async function loadPrecomputedData(task: string, showByDifficulty: boolean): Promise<PrecomputedData | null> {
  const taskKey = task.replace(/\s+/g, '-');
  const cacheKey = showByDifficulty ? `${taskKey}_difficulty` : taskKey;
  
  // Check cache first
  if (precomputedCache.has(cacheKey)) {
    return precomputedCache.get(cacheKey)!;
  }
  
  try {
    // Determine the correct consolidated file name
    let fileName: string;
    if (showByDifficulty) {
      fileName = `${taskKey}_difficulty_consolidated.json`;
    } else {
      fileName = `${taskKey}_consolidated.json`;
    }
    
    const response = await fetch(`/api/direct-files?file=data/precomputed/${fileName}`);
    
    if (!response.ok) {
      console.warn(`Failed to load precomputed data: ${fileName}, status: ${response.status}`);
      return null;
    }
    
    const data: PrecomputedData = await response.json();
    
    // Cache the data
    precomputedCache.set(cacheKey, data);
    
    console.log(`Loaded precomputed data for ${task} (${showByDifficulty ? 'difficulty' : 'normal'}) with ${Object.keys(data).length} models`);
    
    return data;
  } catch (error) {
    console.error(`Error loading precomputed data for ${task}:`, error);
    return null;
  }
}

// Function to get results from precomputed data
export async function getPrecomputedResults(task: string, filters: any, showByDifficulty: boolean): Promise<PrecomputedResult[]> {
  console.log(`ğŸ” getPrecomputedResults called for task: "${task}", showByDifficulty: ${showByDifficulty}`);
  
  const precomputedData = await loadPrecomputedData(task, showByDifficulty);
  
  if (!precomputedData) {
    console.warn(`âŒ No precomputed data available for task: ${task}`);
    return [];
  }
  
  // Generate the combination key for the specific filter combination
  const combinationKey = generateCombinationKey(task, filters, showByDifficulty);
  
  console.log(`ğŸ¯ Looking for combination: "${combinationKey}"`);
  
  // Collect results from all models for this combination
  const results: PrecomputedResult[] = [];
  
  for (const [modelName, modelData] of Object.entries(precomputedData)) {
    const combinationData = modelData[combinationKey];
    
    if (combinationData) {
      // The combinationData is directly the result object, not wrapped in a results array
      results.push({
        ...combinationData,
        model: modelName, // Ensure model name is set correctly
      });
    }
  }
  
  if (results.length === 0) {
    console.warn(`âŒ No results found for combination: "${combinationKey}"`);
    const firstModel = Object.keys(precomputedData)[0];
    const availableCombinations = firstModel ? Object.keys(precomputedData[firstModel]) : [];
    console.log(`ğŸ“‹ Available combinations:`, availableCombinations);
    
    // Try fallback to 'overall' if generated key doesn't work
    if (combinationKey !== 'overall' && availableCombinations.includes('overall')) {
      console.log(`ğŸ”„ Trying fallback to 'overall' combination...`);
      for (const [modelName, modelData] of Object.entries(precomputedData)) {
        const overallData = modelData['overall'];
        if (overallData) {
          results.push({
            ...overallData,
            model: modelName,
          });
        }
      }
      console.log(`ğŸ”„ Fallback results: ${results.length} models`);
    }
  } else {
    console.log(`âœ… Found ${results.length} results for combination: "${combinationKey}"`);
  }
  
  // Sort by rank (should already be sorted, but ensure consistency)
  results.sort((a, b) => (a.rank || 0) - (b.rank || 0));
  
  // Re-assign ranks to ensure they're sequential
  results.forEach((result, index) => {
    result.rank = index + 1;
  });
  
  console.log(`ğŸ¯ Returning ${results.length} results for ${task}`);
  
  return results;
} 