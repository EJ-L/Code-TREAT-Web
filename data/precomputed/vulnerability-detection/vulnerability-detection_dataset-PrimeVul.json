{
  "task": "vulnerability detection",
  "filters": {
    "dataset": [
      "PrimeVul"
    ]
  },
  "showByDifficulty": false,
  "generatedAt": "2025-07-04T03:30:58.806Z",
  "results": [
    {
      "rank": 1,
      "model": "Claude-Sonnet-4",
      "model_url": "https://anthropic.com",
      "Accuracy": "69.3",
      "Precision": "66.8",
      "Recall": "81.7",
      "F1 Score": "73.5",
      "P-C": "-",
      "P-V": "-",
      "P-B": "-",
      "P-R": "-"
    },
    {
      "rank": 2,
      "model": "GPT-4-turbo-2024-04-09",
      "model_url": "",
      "Accuracy": "59.8",
      "Precision": "57.3",
      "Recall": "89.7",
      "F1 Score": "69.9",
      "P-C": "-",
      "P-V": "-",
      "P-B": "-",
      "P-R": "-"
    },
    {
      "rank": 3,
      "model": "Gemini-2.5-Pro-Preview-05-06",
      "model_url": "",
      "Accuracy": "54.7",
      "Precision": "54.5",
      "Recall": "93.1",
      "F1 Score": "68.8",
      "P-C": "-",
      "P-V": "-",
      "P-B": "-",
      "P-R": "-"
    },
    {
      "rank": 4,
      "model": "GPT-4o-2024-11-20",
      "model_url": "https://openai.com/research/gpt-4",
      "Accuracy": "60.3",
      "Precision": "58.3",
      "Recall": "83.3",
      "F1 Score": "68.6",
      "P-C": "-",
      "P-V": "-",
      "P-B": "-",
      "P-R": "-"
    },
    {
      "rank": 5,
      "model": "Claude-3.5-Haiku-20241022",
      "model_url": "",
      "Accuracy": "61.2",
      "Precision": "59.3",
      "Recall": "80.8",
      "F1 Score": "68.4",
      "P-C": "-",
      "P-V": "-",
      "P-B": "-",
      "P-R": "-"
    },
    {
      "rank": 6,
      "model": "Llama-3.1-70B-Instruct",
      "model_url": "",
      "Accuracy": "57.2",
      "Precision": "55.5",
      "Recall": "89.1",
      "F1 Score": "68.4",
      "P-C": "-",
      "P-V": "-",
      "P-B": "-",
      "P-R": "-"
    },
    {
      "rank": 7,
      "model": "Claude-3.5-haiku-20241022",
      "model_url": "",
      "Accuracy": "61.2",
      "Precision": "59.3",
      "Recall": "80.8",
      "F1 Score": "68.4",
      "P-C": "-",
      "P-V": "-",
      "P-B": "-",
      "P-R": "-"
    },
    {
      "rank": 8,
      "model": "Gemma-3-27B-Instruct",
      "model_url": "",
      "Accuracy": "62.0",
      "Precision": "60.6",
      "Recall": "76.9",
      "F1 Score": "67.8",
      "P-C": "-",
      "P-V": "-",
      "P-B": "-",
      "P-R": "-"
    },
    {
      "rank": 9,
      "model": "Llama-3.3-70B-Instruct",
      "model_url": "",
      "Accuracy": "62.3",
      "Precision": "61.6",
      "Recall": "73.4",
      "F1 Score": "67.0",
      "P-C": "-",
      "P-V": "-",
      "P-B": "-",
      "P-R": "-"
    },
    {
      "rank": 10,
      "model": "DeepSeek-R1",
      "model_url": "",
      "Accuracy": "57.8",
      "Precision": "57.6",
      "Recall": "71.8",
      "F1 Score": "63.9",
      "P-C": "-",
      "P-V": "-",
      "P-B": "-",
      "P-R": "-"
    },
    {
      "rank": 11,
      "model": "Gemini-2.5-Pro-Preview-03-25",
      "model_url": "",
      "Accuracy": "57.8",
      "Precision": "58.0",
      "Recall": "68.3",
      "F1 Score": "62.7",
      "P-C": "-",
      "P-V": "-",
      "P-B": "-",
      "P-R": "-"
    },
    {
      "rank": 12,
      "model": "GPT-4.1-2025-04-14",
      "model_url": "",
      "Accuracy": "59.8",
      "Precision": "61.2",
      "Recall": "62.2",
      "F1 Score": "61.7",
      "P-C": "-",
      "P-V": "-",
      "P-B": "-",
      "P-R": "-"
    },
    {
      "rank": 13,
      "model": "Qwen3-235B-A22B",
      "model_url": "",
      "Accuracy": "55.5",
      "Precision": "56.9",
      "Recall": "59.6",
      "F1 Score": "58.2",
      "P-C": "-",
      "P-V": "-",
      "P-B": "-",
      "P-R": "-"
    },
    {
      "rank": 14,
      "model": "Claude-3.5-Sonnet-20241022",
      "model_url": "",
      "Accuracy": "47.7",
      "Precision": "49.9",
      "Recall": "68.9",
      "F1 Score": "57.9",
      "P-C": "-",
      "P-V": "-",
      "P-B": "-",
      "P-R": "-"
    },
    {
      "rank": 15,
      "model": "Claude-3.5-sonnet-20241022",
      "model_url": "",
      "Accuracy": "47.7",
      "Precision": "49.9",
      "Recall": "68.9",
      "F1 Score": "57.9",
      "P-C": "-",
      "P-V": "-",
      "P-B": "-",
      "P-R": "-"
    },
    {
      "rank": 16,
      "model": "DeepSeek-R1 (0528)",
      "model_url": "",
      "Accuracy": "55.8",
      "Precision": "59.7",
      "Recall": "55.5",
      "F1 Score": "57.5",
      "P-C": "-",
      "P-V": "-",
      "P-B": "-",
      "P-R": "-"
    },
    {
      "rank": 17,
      "model": "Grok-3-Mini (High)",
      "model_url": "",
      "Accuracy": "51.2",
      "Precision": "52.6",
      "Recall": "62.5",
      "F1 Score": "57.1",
      "P-C": "-",
      "P-V": "-",
      "P-B": "-",
      "P-R": "-"
    },
    {
      "rank": 18,
      "model": "Grok-3-Mini-Beta (High)",
      "model_url": "",
      "Accuracy": "51.2",
      "Precision": "52.6",
      "Recall": "62.5",
      "F1 Score": "57.1",
      "P-C": "-",
      "P-V": "-",
      "P-B": "-",
      "P-R": "-"
    },
    {
      "rank": 19,
      "model": "Claude-3.7-Sonnet",
      "model_url": "",
      "Accuracy": "61.8",
      "Precision": "69.1",
      "Recall": "48.1",
      "F1 Score": "56.7",
      "P-C": "-",
      "P-V": "-",
      "P-B": "-",
      "P-R": "-"
    },
    {
      "rank": 20,
      "model": "Qwen3-32B",
      "model_url": "",
      "Accuracy": "53.5",
      "Precision": "56.5",
      "Recall": "46.2",
      "F1 Score": "50.8",
      "P-C": "-",
      "P-V": "-",
      "P-B": "-",
      "P-R": "-"
    },
    {
      "rank": 21,
      "model": "o4-mini (Med)",
      "model_url": "",
      "Accuracy": "56.3",
      "Precision": "64.6",
      "Recall": "36.2",
      "F1 Score": "46.4",
      "P-C": "-",
      "P-V": "-",
      "P-B": "-",
      "P-R": "-"
    },
    {
      "rank": 22,
      "model": "Llama-3.1-8B-Instruct",
      "model_url": "",
      "Accuracy": "54.5",
      "Precision": "61.5",
      "Recall": "33.3",
      "F1 Score": "43.2",
      "P-C": "-",
      "P-V": "-",
      "P-B": "-",
      "P-R": "-"
    },
    {
      "rank": 23,
      "model": "Qwen3-30B-A3B",
      "model_url": "",
      "Accuracy": "54.0",
      "Precision": "61.5",
      "Recall": "30.8",
      "F1 Score": "41.0",
      "P-C": "-",
      "P-V": "-",
      "P-B": "-",
      "P-R": "-"
    },
    {
      "rank": 24,
      "model": "DeepSeek-V3",
      "model_url": "",
      "Accuracy": "51.5",
      "Precision": "63.6",
      "Recall": "15.7",
      "F1 Score": "25.2",
      "P-C": "-",
      "P-V": "-",
      "P-B": "-",
      "P-R": "-"
    },
    {
      "rank": 25,
      "model": "Qwen2.5-72B-Instruct",
      "model_url": "",
      "Accuracy": "52.3",
      "Precision": "73.2",
      "Recall": "13.1",
      "F1 Score": "22.3",
      "P-C": "-",
      "P-V": "-",
      "P-B": "-",
      "P-R": "-"
    },
    {
      "rank": 26,
      "model": "o3-mini (Med)",
      "model_url": "",
      "Accuracy": "50.5",
      "Precision": "61.5",
      "Recall": "12.8",
      "F1 Score": "21.2",
      "P-C": "-",
      "P-V": "-",
      "P-B": "-",
      "P-R": "-"
    },
    {
      "rank": 27,
      "model": "Qwen2.5-Coder-32B-Instruct",
      "model_url": "",
      "Accuracy": "51.7",
      "Precision": "70.4",
      "Recall": "12.2",
      "F1 Score": "20.8",
      "P-C": "-",
      "P-V": "-",
      "P-B": "-",
      "P-R": "-"
    },
    {
      "rank": 28,
      "model": "Qwen2.5-32B-Instruct",
      "model_url": "",
      "Accuracy": "51.7",
      "Precision": "70.4",
      "Recall": "12.2",
      "F1 Score": "20.8",
      "P-C": "-",
      "P-V": "-",
      "P-B": "-",
      "P-R": "-"
    },
    {
      "rank": 29,
      "model": "Llama-4-Scout-17B-16E-Instruct",
      "model_url": "",
      "Accuracy": "49.0",
      "Precision": "55.1",
      "Recall": "12.2",
      "F1 Score": "19.9",
      "P-C": "-",
      "P-V": "-",
      "P-B": "-",
      "P-R": "-"
    },
    {
      "rank": 30,
      "model": "GPT-3.5-turbo-0125",
      "model_url": "",
      "Accuracy": "45.8",
      "Precision": "40.8",
      "Recall": "9.3",
      "F1 Score": "15.1",
      "P-C": "-",
      "P-V": "-",
      "P-B": "-",
      "P-R": "-"
    }
  ],
  "metadata": {
    "totalResults": 30,
    "hasResults": true
  }
}