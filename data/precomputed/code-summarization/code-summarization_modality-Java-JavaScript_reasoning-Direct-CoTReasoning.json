{
  "task": "code summarization",
  "filters": {
    "modality": [
      "Java",
      "JavaScript"
    ],
    "reasoning": [
      "Direct",
      "CoT Reasoning"
    ]
  },
  "showByDifficulty": false,
  "generatedAt": "2025-07-03T15:30:06.695Z",
  "results": [
    {
      "rank": 1,
      "model": "Claude-3.5-Sonnet-20241022",
      "model_url": "",
      "LLM Judge": "96.4"
    },
    {
      "rank": 2,
      "model": "Llama3.3-70B-Instruct",
      "model_url": "",
      "LLM Judge": "96.1"
    },
    {
      "rank": 3,
      "model": "Qwen3-235B-A22B",
      "model_url": "",
      "LLM Judge": "95.7"
    },
    {
      "rank": 4,
      "model": "Claude-Sonnet-4",
      "model_url": "https://anthropic.com",
      "LLM Judge": "94.3"
    },
    {
      "rank": 5,
      "model": "DeepSeek-V3",
      "model_url": "",
      "LLM Judge": "92.0"
    },
    {
      "rank": 6,
      "model": "DeepSeek-R1",
      "model_url": "",
      "LLM Judge": "89.9"
    },
    {
      "rank": 7,
      "model": "Qwen3-32B",
      "model_url": "",
      "LLM Judge": "89.0"
    },
    {
      "rank": 8,
      "model": "GPT-4-turbo-2024-04-09",
      "model_url": "",
      "LLM Judge": "88.8"
    },
    {
      "rank": 9,
      "model": "Qwen2.5-Coder-32B-Instruct",
      "model_url": "",
      "LLM Judge": "87.1"
    },
    {
      "rank": 10,
      "model": "Claude-3.5-Haiku-20241022",
      "model_url": "",
      "LLM Judge": "86.9"
    },
    {
      "rank": 11,
      "model": "GPT-4o-2024-11-20",
      "model_url": "https://openai.com/research/gpt-4",
      "LLM Judge": "86.8"
    },
    {
      "rank": 12,
      "model": "Claude-3.7-Sonnet",
      "model_url": "",
      "LLM Judge": "86.3"
    },
    {
      "rank": 13,
      "model": "DeepSeek-R1 (0528)",
      "model_url": "",
      "LLM Judge": "85.5"
    },
    {
      "rank": 14,
      "model": "Qwen2.5-72B-Instruct",
      "model_url": "",
      "LLM Judge": "85.5"
    },
    {
      "rank": 15,
      "model": "Grok-3-Mini (High)",
      "model_url": "",
      "LLM Judge": "85.0"
    },
    {
      "rank": 16,
      "model": "o3-mini (Med)",
      "model_url": "",
      "LLM Judge": "84.8"
    },
    {
      "rank": 17,
      "model": "o4-mini (Med)",
      "model_url": "",
      "LLM Judge": "84.5"
    },
    {
      "rank": 18,
      "model": "Gemma-3-27B-Instruct",
      "model_url": "",
      "LLM Judge": "82.9"
    },
    {
      "rank": 19,
      "model": "GPT-4.1-2025-04-14",
      "model_url": "",
      "LLM Judge": "80.7"
    },
    {
      "rank": 20,
      "model": "Qwen3-30B-A3B",
      "model_url": "",
      "LLM Judge": "79.7"
    },
    {
      "rank": 21,
      "model": "Gemini-2.5-Pro-Preview-05-06",
      "model_url": "",
      "LLM Judge": "78.1"
    },
    {
      "rank": 22,
      "model": "Llama-4-Scout-17B-16E-Instruct",
      "model_url": "",
      "LLM Judge": "75.4"
    },
    {
      "rank": 23,
      "model": "Llama-3.1-70B-Instruct",
      "model_url": "",
      "LLM Judge": "75.4"
    },
    {
      "rank": 24,
      "model": "GPT-3.5-turbo-0125",
      "model_url": "",
      "LLM Judge": "69.7"
    },
    {
      "rank": 25,
      "model": "Llama-3.1-8B-Instruct",
      "model_url": "",
      "LLM Judge": "64.2"
    }
  ],
  "metadata": {
    "totalResults": 25,
    "hasResults": true
  }
}